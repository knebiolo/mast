{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39725c4",
   "metadata": {},
   "source": [
    "# MAST \n",
    "## Movement Analysis Software for Telemetry Data\n",
    "\n",
    "This project notebook will guide the end user through a complete telemetry project, from setup, to data import, false positive reduction, and 1D movement analysis.  This notebook and software was designed so that the end user can complete a telemetry project in multiple sessions.  Some cells need to be re-run every session, while others will only be run once.  Please read and understand all directions before proceeding.\n",
    "\n",
    "# Part 1: Project Setup\n",
    "\n",
    "The steps in Part 1 need to be re-run every session.\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bff69",
   "metadata": {},
   "source": [
    "Identify MAST software directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96e303cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"C:\\Users\\Nicole Haibach\\Kleinschmidt Associates, Inc\\Kevin Nebiolo - mast\\pymast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53f911",
   "metadata": {},
   "source": [
    "Import MAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9240617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymast.radio_project import radio_project\n",
    "from pymast import formatter as formatter\n",
    "import pymast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103c6ee",
   "metadata": {},
   "source": [
    "# Create a MAST Project\n",
    "\n",
    "We designed MAST so that the end user can complete a telemetry project in multiple sessions.  After a work session is complete, there is no need to save the data or close the project.  Just shut down the notebook, the data has already been saved to the background HDF file.  When you start a new session, re-run this cell, MAST will not save over your previous session.  Please see the project ReadMe for instructions on creating the input data files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5968d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = r\"C:\\Users\\Nicole Haibach\\OneDrive - Kleinschmidt Associates, Inc\\Desktop\\MAST\"\n",
    "db_name = 'MAST_Part2'\n",
    "detection_count = 5\n",
    "duration = 1\n",
    "tag_data = pd.read_csv(os.path.join(project_dir,'tblMasterTag.csv'))\n",
    "receiver_data = pd.read_csv(os.path.join(project_dir,'tblMasterReceiver.csv'))\n",
    "nodes_data = pd.read_csv(os.path.join(project_dir,'tblNodes.csv'))\n",
    "\n",
    "# create a project\n",
    "project = radio_project(project_dir,\n",
    "                        db_name,\n",
    "                        detection_count,\n",
    "                        duration,\n",
    "                        tag_data,\n",
    "                        receiver_data,\n",
    "                        nodes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758de9b",
   "metadata": {},
   "source": [
    "# Part 2: Data management and False Positive Reduction\n",
    "\n",
    "## Import Raw Telemetry Data\n",
    "\n",
    "This cell **does not** need to be rerun every session.  \n",
    "\n",
    "To import raw telemetry data, update the parameters and run the cell for every receiver in your project\n",
    "\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type, we currently have parsers for 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'\n",
    "3. scan_time: if the Receiver Type is 'orion' or 'ares', enter channel scan time in seconds if any, otherwise keep 1\n",
    "4. channels: if the Receiver Type is 'orion' or 'ares', enter the number of channels if any, otherwise keep 1\n",
    "5. antenna_to_receiver_dict: both SigmaEight and Lotek associate one or more antennas to a single receiver.  This dictionary makes that association.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab024de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start importing file 03-052015.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Casting to unit-less dtype 'datetime64' is not supported. Pass e.g. 'datetime64[ns]' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m antenna_to_rec_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA0\u001b[39m\u001b[38;5;124m'\u001b[39m:rec_id}\n\u001b[1;32m----> 9\u001b[0m project\u001b[38;5;241m.\u001b[39mtelem_data_import(rec_id,\n\u001b[0;32m     10\u001b[0m                           rec_type,\n\u001b[0;32m     11\u001b[0m                           training_dir,\n\u001b[0;32m     12\u001b[0m                           db_dir,\n\u001b[0;32m     13\u001b[0m                           scan_time,\n\u001b[0;32m     14\u001b[0m                           channels,\n\u001b[0;32m     15\u001b[0m                           antenna_to_rec_dict)\n",
      "File \u001b[1;32m~\\Kleinschmidt Associates, Inc\\Kevin Nebiolo - mast\\pymast\\radio_project.py:156\u001b[0m, in \u001b[0;36mradio_project.telem_data_import\u001b[1;34m(self, rec_id, rec_type, file_dir, db_dir, scan_time, channels, ant_to_rec_dict)\u001b[0m\n\u001b[0;32m    153\u001b[0m     parsers\u001b[38;5;241m.\u001b[39msrx600(f_dir, db_dir, rec_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy_tags, scan_time \u001b[38;5;241m=\u001b[39m scan_time, channels \u001b[38;5;241m=\u001b[39m channels, ant_to_rec_dict \u001b[38;5;241m=\u001b[39m ant_to_rec_dict)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m rec_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrx800\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 156\u001b[0m     parsers\u001b[38;5;241m.\u001b[39msrx800(f_dir, db_dir, rec_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy_tags, scan_time \u001b[38;5;241m=\u001b[39m scan_time, channels \u001b[38;5;241m=\u001b[39m channels, ant_to_rec_dict \u001b[38;5;241m=\u001b[39m ant_to_rec_dict)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m rec_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrx1200\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    159\u001b[0m     parsers\u001b[38;5;241m.\u001b[39msrx1200(f_dir, db_dir, rec_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy_tags, scan_time \u001b[38;5;241m=\u001b[39m scan_time, channels \u001b[38;5;241m=\u001b[39m channels, ant_to_rec_dict \u001b[38;5;241m=\u001b[39m ant_to_rec_dict)\n",
      "File \u001b[1;32m~\\Kleinschmidt Associates, Inc\\Kevin Nebiolo - mast\\pymast\\parsers.py:891\u001b[0m, in \u001b[0;36msrx800\u001b[1;34m(file_name, db_dir, rec_id, study_tags, scan_time, channels, ant_to_rec_dict)\u001b[0m\n\u001b[0;32m    888\u001b[0m telem_dat_sub\u001b[38;5;241m.\u001b[39mreset_index(inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;66;03m# write to hdf\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m telem_dat_sub \u001b[38;5;241m=\u001b[39m telem_dat_sub\u001b[38;5;241m.\u001b[39mastype({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    892\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq_code\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    893\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_stamp\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    894\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscan_time\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    895\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    896\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec_type\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    897\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    898\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    899\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec_id\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m    901\u001b[0m telem_dat_sub\u001b[38;5;241m.\u001b[39mreset_index(inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    903\u001b[0m telem_dat_sub \u001b[38;5;241m=\u001b[39m telem_dat_sub[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    904\u001b[0m                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_stamp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    905\u001b[0m                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    911\u001b[0m                                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec_type\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:6513\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6512\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6513\u001b[0m         res_col \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mcdt, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6514\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   6515\u001b[0m         ex\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   6516\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Error while type casting for column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   6517\u001b[0m         )\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:180\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\Anaconda\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:720\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .astype to convert from timezone-aware dtype to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone-naive dtype. Use obj.tz_localize(None) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    711\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj.tz_convert(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).tz_localize(None) instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    712\u001b[0m     )\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_unitless(dtype)\n\u001b[0;32m    719\u001b[0m ):\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCasting to unit-less dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass e.g. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m     )\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, PeriodDtype):\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_period(freq\u001b[38;5;241m=\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfreq)\n",
      "\u001b[1;31mTypeError\u001b[0m: Casting to unit-less dtype 'datetime64' is not supported. Pass e.g. 'datetime64[ns]' instead."
     ]
    }
   ],
   "source": [
    "rec_id = 'T03'\n",
    "rec_type = 'srx800'\n",
    "training_dir = os.path.join(project_dir,'Data','Training_Files')\n",
    "db_dir = os.path.join(project_dir,'%s.h5'%(db_name))\n",
    "scan_time = 1.         \n",
    "channels = 1\n",
    "antenna_to_rec_dict = {'A0':rec_id}\n",
    "\n",
    "project.telem_data_import(rec_id,\n",
    "                          rec_type,\n",
    "                          training_dir,\n",
    "                          db_dir,\n",
    "                          scan_time,\n",
    "                          channels,\n",
    "                          antenna_to_rec_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90dd541",
   "metadata": {},
   "source": [
    "### Undo Import\n",
    "\n",
    "Sometimes thing's go wrong, sometimes the parameters you entered are incorrect.  Undo the import you just did with this cell.  \n",
    "\n",
    "Note **you only run the cell when you need to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_import(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0deaf",
   "metadata": {},
   "source": [
    "## Create Training Data\n",
    "\n",
    "This cell does **not** need to be run every work session\n",
    "\n",
    "To train data, update the following parameters for your telemetry project.  Repeat this cell until data from all receivers have been trained.\n",
    "\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type,  we currently have parsers for and can train and classify 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters and get a list of fish to iterate over\n",
    "rec_id = 'R020'\n",
    "rec_type = 'orion'\n",
    "fishes = project.get_fish(rec_id = rec_id)\n",
    "\n",
    "# iterate over fish and train\n",
    "for fish in fishes:\n",
    "    project.train(fish, rec_id)\n",
    "\n",
    "# generate summary statistics\n",
    "project.training_summary(rec_type, site = [rec_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae90d3",
   "metadata": {},
   "source": [
    "### Undo Training\n",
    "\n",
    "**Run the following cell only when you need to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_training(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753fdee",
   "metadata": {},
   "source": [
    "## Classify a Receiver's Data\n",
    "\n",
    "This cell can be run as many times as needed.  \n",
    "\n",
    "To classify data, update the following parameters and run the cell.\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type,  we currently have parsers for and can train and classify 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'\n",
    "3. class_iter: the Classification Iteration, it is possible to reclassify a receiver's data and iterate until convergence.  Leave 'Null' for the first iteration, then start with 1 and number sequentially by 1 until covergence.\n",
    "4. threshold_ratio: the default threshold ratio is 1.0 for the maximum a posteriori hypothesis.  a threshold ratio > 1.0 requires requires more weight of evidence for a record to be classified as true.  likewise a threshold ratio < 1.0 is less strict and may accept marginal detections as being true.\n",
    "5. fields: the likelihood function is A-La Carte, it is possible to build a model with the following predictors: 'cons_length','cons_length','hit_ratio','noise_ratio','series_hit','power', and 'lag_diff'.  Note MAST requires at least 1 predictor to classify data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32368df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters and get a list of fish to iterate over\n",
    "rec_id = 'R020'\n",
    "rec_type = 'orion'\n",
    "class_iter = 2 # start with none - if we need more classifications then 2\n",
    "fishes = project.get_fish(rec_id = rec_id, \n",
    "                          train = False, \n",
    "                          reclass_iter = class_iter)\n",
    "threshold_ratio = 1.0 # 1.0 = MAP Hypothesis\n",
    "\n",
    "# then generate training data for the classifier\n",
    "training_data = project.create_training_data(rec_type,class_iter)#,[rec_id])\n",
    "\n",
    "# next, create your A-La Carte Likelihood function\n",
    "# fields = ['cons_length','cons_length','hit_ratio','noise_ratio','series_hit','power','lag_diff']\n",
    "fields = ['hit_ratio','cons_length','noise_ratio','power','lag_diff']\n",
    "\n",
    "# iterate over fish and classify\n",
    "for fish in fishes:\n",
    "    project.classify(fish,rec_id,fields,training_data,class_iter,threshold_ratio)\n",
    "\n",
    "# generate summary statistics\n",
    "project.classification_summary(rec_id, class_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40d1c0",
   "metadata": {},
   "source": [
    "### Undo Classification \n",
    "\n",
    "Lots can go wrong during classification, the likelihood model may have included conflicted predictors, the threshold ratio was too strict, or the iteration was wrong.  In any case, run the following cell when you need a redo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_classification(rec_id, class_iter = class_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925dd48",
   "metadata": {},
   "source": [
    "## Identify Bouts\n",
    "\n",
    "The following steps (Bouts and Presences) are not required for a MAST project.  They are powerful tools that will assist with modeling movement. \n",
    "To identify bouts at one of the nodes in your project, update the following parameters.  It is advised to identify bouts at nodes one at a time because model fitting requires user interaction.  MAST will ask the researcher to identify the number of knots that may be present in the data.  The presence method can either use the result of hte threshold method, or can accept a user identify threshold value (float).  \n",
    "\n",
    "1. node: A Node in your project that may consist of one or more receivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef339ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodes\n",
    "node = 'R020'\n",
    "\n",
    "# create a bout object\n",
    "bout = mast.bout(project, node, 2, 21600)\n",
    "    \n",
    "# Find the threshold\n",
    "threshold = bout.fit_processes()\n",
    "\n",
    "# calculate presences - or pass float\n",
    "bout.presence(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1eed79",
   "metadata": {},
   "source": [
    "### Undo Bouts and Presence\n",
    "\n",
    "The bout process involves trial and error.  To undo, run the following cell only when you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d86543",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_bouts(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dd08c",
   "metadata": {},
   "source": [
    "## Reduce Overlap\n",
    "\n",
    "With presences at receivers, it is possible to reduce overlap between receivers and put a fish in an exact place and time.  For example, it is possible to place a dipole receiver so it's detection range is completely within the area covered by a large aerial Yagi.  When a fish is present at the Dipole receiver and Yagi receiver at the same we can remove those overlapping detections at the Yagi receiver.  This is useful for modeling movement from a large area into a discrete location, like tailrace to upstream passage entrance.  \n",
    "\n",
    "The overlap function requires the end user to identify the following parameters:\n",
    "1. edges: List of tuples (network edges) that represent parent:child or Yagi:dipole relationships in your data\n",
    "2. nodes: List of nodes in your project, note nodes may be made up of one or more receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edges showing parent:child relationships for nodes in network\n",
    "edges = [('R010','R013'),('R010','R014'),('R010','R015'),('R010','R016'),('R010','R017'),('R010','R018'),\n",
    "          ('R019','R013'),('R019','R014'),('R019','R015'),('R019','R016'),('R019','R017'),('R019','R018'),\n",
    "          ('R020','R013'),('R020','R014'),('R020','R015'),('R020','R016'),('R020','R017'),('R020','R018')]\n",
    "\n",
    "nodes = ['R010','R019','R020','R013','R014','R015','R016','R017','R018']\n",
    "    \n",
    "# create an overlap object and apply nested doll algorithm\n",
    "doll = mast.overlap_reduction(nodes, edges, project)\n",
    "doll.nested_doll()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53467fa1",
   "metadata": {},
   "source": [
    "## Make Recaptures Table\n",
    "\n",
    "The last step in the data management section is to aggregate data into a recaptures table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eee09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.make_recaptures_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd1a09",
   "metadata": {},
   "source": [
    "# Part 3: Analysis of Movement\n",
    "\n",
    "The following cells assist researchers with analyzing movement between receivers.  It is useful to reconstruct the receivers in your project into a network schematic that describes the possible movement pathways between receivers. Therefore, movement is 1D.  MAST has functions that can prepare data for Time to Event Analysis with Competing Risks, Multi State Markov Models, Cormack Jolly Seber Mark Recapture, and Live Recapture Dead Recovery Mark Recapture.  \n",
    "\n",
    "## Model 1D Movement with Competing Risks and Multi-State Markov Models\n",
    "\n",
    "The first step in modeling multi-state models with a Time to Event framework is to associate project nodes with states in the model.  This is done with the node_to_state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create models using a Time to Event Framework\n",
    "    \n",
    "# what is the Node to State relationship - use Python dictionary\n",
    "node_to_state = {'R001':1,'R002':1,                   # upstream\n",
    "                 'R012':2,                            # forebay\n",
    "                 'R013':3,'R015':3,'R016':3,'R017':3, # powerhouse\n",
    "                 'R018':4,                            # sluice\n",
    "                 'R003':5,                            # east channel up\n",
    "                 'R007':6,                            # east channel down\n",
    "                 'R008':7,                            # east channel dam\n",
    "                 'R009':8,                            # NLF\n",
    "                 'R010':9,'R019':19,                  # tailrace\n",
    "                 'R011':10,                           # downstream\n",
    "                 'R004':11,'R005':11}                 # downstream 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aef50e",
   "metadata": {},
   "source": [
    "Then we create a Time to Event data object.  Note that there are a number of optional arguments that can be passed to the time to event data object.  If initial_state_release is set to True, a state (state: 0) is added to the model.  Therefore it is possible to model movement from the release location as well as determine fall back.  If last_presence_time0 is set to True, the last detection at the initial receiver is used as the starting time for the analysis of movement.  When modeling migratory movement of American Shad for example, adult fish can survive spawning.  Thus it can be recaptured at the same reciever on its way up and down.  If you are modeling downstream movement, you want to model movement from when it was last at the most upstream receiver.  Cap_loc and rel_loc are optional arguments that will filter the data in the model so it only looks at specimens at specific capture and release locations.  And finally, the species argument restricts model creation to a single species if more than 1 were tagged in your study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tte = formatter.time_to_event(node_to_state,\n",
    "                              project,\n",
    "                              initial_state_release = False, \n",
    "                              last_presence_time0 = False, \n",
    "                              cap_loc = None,\n",
    "                              rel_loc = None, \n",
    "                              species = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97c015",
   "metadata": {},
   "source": [
    "Then we perform data preparation.  When the time_dependent_covariates = True, MAST creates an output file that can be joined to time series data.  The bucket_length_min argument specifies the number of minutes between each time series observation.  Unknown_state places fish into a new 'unknown' state if they went missing before they reached their goal by the studies completion. Overlap may still exist between receivers and adjacency_filter removes those movements that still may exist.  This commonly happens when forebay receivers pick up fish in the tailrace.  When looking at transitions it appears that a fish has instantlh moved from the tailrace to the forebay.  To the algorithm, the forebay detections look like real detections, but when we model movement they must be removed.  The relationships in the filter specify the parent:child relationshp or to:from movements that are illegal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80177050",
   "metadata": {},
   "outputs": [],
   "source": [
    "tte.data_prep(project,\n",
    "              time_dependent_covariates = True,\n",
    "              unknown_state = None,\n",
    "              bucket_length_min = 15,\n",
    "              adjacency_filter = [('R010','R013'),('R010','R014'),('R010','R015'),('R010','R016'),('R010','R017'),('R010','R018'),\n",
    "                                  ('R019','R013'),('R019','R014'),('R019','R015'),('R019','R016'),('R019','R017'),('R019','R018'),\n",
    "                                  ('R020','R013'),('R020','R014'),('R020','R015'),('R020','R016'),('R020','R017'),('R020','R018')])\n",
    "# Step 4, generate a summary\n",
    "tte.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
