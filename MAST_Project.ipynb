{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39725c4",
   "metadata": {},
   "source": [
    "# MAST \n",
    "## Movement Analysis Software for Telemetry Data\n",
    "\n",
    "This project notebook will guide the end user through a complete telemetry project, from setup, to data import, false positive reduction, and 1D movement analysis.  This notebook and software was designed so that the end user can complete a telemetry project in multiple sessions.  Some cells need to be re-run every session, while others will only be run once.  Please read and understand all directions before proceeding.\n",
    "\n",
    "# Part 1: Project Setup\n",
    "\n",
    "The steps in Part 1 need to be re-run every session.\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bff69",
   "metadata": {},
   "source": [
    "Identify MAST software directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e303cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"C:\\Users\\knebiolo\\OneDrive - Kleinschmidt Associates, Inc\\Personal\\Articles for Submission\\MAST Part 2\\mast\\pymast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53f911",
   "metadata": {},
   "source": [
    "Import MAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9240617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymast.radio_project import radio_project\n",
    "from pymast import formatter as formatter\n",
    "import pymast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103c6ee",
   "metadata": {},
   "source": [
    "# Create a MAST Project\n",
    "\n",
    "We designed MAST so that the end user can complete a telemetry project in multiple sessions.  After a work session is complete, there is no need to save the data or close the project.  Just shut down the notebook, the data has already been saved to the background HDF file.  When you start a new session, re-run this cell, MAST will not save over your previous session.  Please see the project ReadMe for instructions on creating the input data files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5968d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = r\"C:\\Users\\knebiolo\\OneDrive - Kleinschmidt Associates, Inc\\Personal\\Articles for Submission\\MAST Part 2\"\n",
    "db_name = 'MAST_Part2'\n",
    "detection_count = 5\n",
    "duration = 1\n",
    "tag_data = pd.read_csv(os.path.join(project_dir,'tblMasterTag.csv'))\n",
    "receiver_data = pd.read_csv(os.path.join(project_dir,'tblMasterReceiver.csv'))\n",
    "nodes_data = pd.read_csv(os.path.join(project_dir,'tblNodes.csv'))\n",
    "\n",
    "# create a project\n",
    "project = radio_project(project_dir,\n",
    "                        db_name,\n",
    "                        detection_count,\n",
    "                        duration,\n",
    "                        tag_data,\n",
    "                        receiver_data,\n",
    "                        nodes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758de9b",
   "metadata": {},
   "source": [
    "# Part 2: Data management and False Positive Reduction\n",
    "\n",
    "## Import Raw Telemetry Data\n",
    "\n",
    "This cell **does not** need to be rerun every session.  \n",
    "\n",
    "To import raw telemetry data, update the parameters and run the cell for every receiver in your project\n",
    "\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type, we currently have parsers for 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'\n",
    "3. scan_time: if the Receiver Type is 'orion' or 'ares', enter channel scan time in seconds if any, otherwise keep 1\n",
    "4. channels: if the Receiver Type is 'orion' or 'ares', enter the number of channels if any, otherwise keep 1\n",
    "5. antenna_to_receiver_dict: both SigmaEight and Lotek associate one or more antennas to a single receiver.  This dictionary makes that association.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab024de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start importing file 03-052015.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 03-052015.TXT imported\n",
      "start importing file 03-060215.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 03-060215.TXT imported\n",
      "start importing file 03-061815rev1.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 03-061815rev1.TXT imported\n",
      "start importing file 03-062315.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 03-062315.TXT imported\n",
      "start importing file 03-070215.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 03-070215.TXT imported\n",
      "start importing file 03-Montague Wastwater- 071415.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 03-Montague Wastwater- 071415.TXT imported\n",
      "start importing file 3-052915.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 3-052915.TXT imported\n",
      "start importing file 3-061115.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File 3-061115.TXT imported\n",
      "start importing file Montague waterwater-081315.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File Montague waterwater-081315.TXT imported\n",
      "start importing file waste-070715.TXT\n",
      "parsing SRX800 header complete\n",
      "data import complete\n",
      "Data standardized and exported to hdf\n",
      "File waste-070715.TXT imported\n",
      "Raw Telemetry Data Import Completed\n"
     ]
    }
   ],
   "source": [
    "rec_id = 'T03'\n",
    "rec_type = 'srx800'\n",
    "training_dir = os.path.join(project_dir,'Data','Training_Files')\n",
    "db_dir = os.path.join(project_dir,'%s.h5'%(db_name))\n",
    "scan_time = 1.         \n",
    "channels = 1\n",
    "antenna_to_rec_dict = {'A0':rec_id}\n",
    "\n",
    "project.telem_data_import(rec_id,\n",
    "                          rec_type,\n",
    "                          training_dir,\n",
    "                          db_dir,\n",
    "                          scan_time,\n",
    "                          channels,\n",
    "                          antenna_to_rec_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90dd541",
   "metadata": {},
   "source": [
    "### Undo Import\n",
    "\n",
    "Sometimes thing's go wrong, sometimes the parameters you entered are incorrect.  Undo the import you just did with this cell.  \n",
    "\n",
    "Note **you only run the cell when you need to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_import(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0deaf",
   "metadata": {},
   "source": [
    "## Create Training Data\n",
    "\n",
    "This cell does **not** need to be run every work session\n",
    "\n",
    "To train data, update the following parameters for your telemetry project.  Repeat this cell until data from all receivers have been trained.\n",
    "\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type,  we currently have parsers for and can train and classify 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b4bc4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'T03'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'T03'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# iterate over fish and train\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fish \u001b[38;5;129;01min\u001b[39;00m fishes:\n\u001b[1;32m----> 8\u001b[0m     project\u001b[38;5;241m.\u001b[39mtrain(fish, rec_id)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# generate summary statistics\u001b[39;00m\n\u001b[0;32m     11\u001b[0m project\u001b[38;5;241m.\u001b[39mtraining_summary(rec_type, site \u001b[38;5;241m=\u001b[39m [rec_id])\n",
      "File \u001b[1;32m~\\OneDrive - Kleinschmidt Associates, Inc\\Personal\\Articles for Submission\\MAST Part 2\\mast\\pymast\\radio_project.py:227\u001b[0m, in \u001b[0;36mradio_project.train\u001b[1;34m(self, freq_code, rec_id)\u001b[0m\n\u001b[0;32m    222\u001b[0m train_dat\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_stamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    223\u001b[0m                           keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    224\u001b[0m                           inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# set some object variables\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m rec_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreceivers\u001b[38;5;241m.\u001b[39mat[rec_id,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# for training data, we know the tag's detection class ahead of time,\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# if the tag is in the study tag list, it is a known detection class, if\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# it is a beacon tag, it is definite, if it is a study tag, it's plausible\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq_code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy_tags:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2488\u001b[0m, in \u001b[0;36m_AtIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m-> 2488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2440\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2439\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_key(key)\n\u001b[1;32m-> 2440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4012\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4006\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   4008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   4009\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   4010\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   4011\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 4012\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(index)\n\u001b[0;32m   4013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   4015\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   4016\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'T03'"
     ]
    }
   ],
   "source": [
    "# set parameters and get a list of fish to iterate over\n",
    "rec_id = 'T03'\n",
    "rec_type = 'srx800'\n",
    "fishes = project.get_fish(rec_id = rec_id)\n",
    "\n",
    "# iterate over fish and train\n",
    "for fish in fishes:\n",
    "    project.train(fish, rec_id)\n",
    "\n",
    "# generate summary statistics\n",
    "project.training_summary(rec_type, site = [rec_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae90d3",
   "metadata": {},
   "source": [
    "### Undo Training\n",
    "\n",
    "**Run the following cell only when you need to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_training(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753fdee",
   "metadata": {},
   "source": [
    "## Classify a Receiver's Data\n",
    "\n",
    "This cell can be run as many times as needed.  \n",
    "\n",
    "To classify data, update the following parameters and run the cell.\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type,  we currently have parsers for and can train and classify 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'\n",
    "3. class_iter: the Classification Iteration, it is possible to reclassify a receiver's data and iterate until convergence.  Leave 'Null' for the first iteration, then start with 1 and number sequentially by 1 until covergence.\n",
    "4. threshold_ratio: the default threshold ratio is 1.0 for the maximum a posteriori hypothesis.  a threshold ratio > 1.0 requires requires more weight of evidence for a record to be classified as true.  likewise a threshold ratio < 1.0 is less strict and may accept marginal detections as being true.\n",
    "5. fields: the likelihood function is A-La Carte, it is possible to build a model with the following predictors: 'cons_length','cons_length','hit_ratio','noise_ratio','series_hit','power', and 'lag_diff'.  Note MAST requires at least 1 predictor to classify data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32368df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters and get a list of fish to iterate over\n",
    "rec_id = 'R020'\n",
    "rec_type = 'orion'\n",
    "class_iter = 2 # start with none - if we need more classifications then 2\n",
    "fishes = project.get_fish(rec_id = rec_id, \n",
    "                          train = False, \n",
    "                          reclass_iter = class_iter)\n",
    "threshold_ratio = 1.0 # 1.0 = MAP Hypothesis\n",
    "\n",
    "# then generate training data for the classifier\n",
    "training_data = project.create_training_data(rec_type,class_iter)#,[rec_id])\n",
    "\n",
    "# next, create your A-La Carte Likelihood function\n",
    "# fields = ['cons_length','cons_length','hit_ratio','noise_ratio','series_hit','power','lag_diff']\n",
    "fields = ['hit_ratio','cons_length','noise_ratio','power','lag_diff']\n",
    "\n",
    "# iterate over fish and classify\n",
    "for fish in fishes:\n",
    "    project.classify(fish,rec_id,fields,training_data,class_iter,threshold_ratio)\n",
    "\n",
    "# generate summary statistics\n",
    "project.classification_summary(rec_id, class_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40d1c0",
   "metadata": {},
   "source": [
    "### Undo Classification \n",
    "\n",
    "Lots can go wrong during classification, the likelihood model may have included conflicted predictors, the threshold ratio was too strict, or the iteration was wrong.  In any case, run the following cell when you need a redo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_classification(rec_id, class_iter = class_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925dd48",
   "metadata": {},
   "source": [
    "## Identify Bouts\n",
    "\n",
    "The following steps (Bouts and Presences) are not required for a MAST project.  They are powerful tools that will assist with modeling movement. \n",
    "To identify bouts at one of the nodes in your project, update the following parameters.  It is advised to identify bouts at nodes one at a time because model fitting requires user interaction.  MAST will ask the researcher to identify the number of knots that may be present in the data.  The presence method can either use the result of hte threshold method, or can accept a user identify threshold value (float).  \n",
    "\n",
    "1. node: A Node in your project that may consist of one or more receivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef339ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodes\n",
    "node = 'R020'\n",
    "\n",
    "# create a bout object\n",
    "bout = mast.bout(project, node, 2, 21600)\n",
    "    \n",
    "# Find the threshold\n",
    "threshold = bout.fit_processes()\n",
    "\n",
    "# calculate presences - or pass float\n",
    "bout.presence(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1eed79",
   "metadata": {},
   "source": [
    "### Undo Bouts and Presence\n",
    "\n",
    "The bout process involves trial and error.  To undo, run the following cell only when you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d86543",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_bouts(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dd08c",
   "metadata": {},
   "source": [
    "## Reduce Overlap\n",
    "\n",
    "With presences at receivers, it is possible to reduce overlap between receivers and put a fish in an exact place and time.  For example, it is possible to place a dipole receiver so it's detection range is completely within the area covered by a large aerial Yagi.  When a fish is present at the Dipole receiver and Yagi receiver at the same we can remove those overlapping detections at the Yagi receiver.  This is useful for modeling movement from a large area into a discrete location, like tailrace to upstream passage entrance.  \n",
    "\n",
    "The overlap function requires the end user to identify the following parameters:\n",
    "1. edges: List of tuples (network edges) that represent parent:child or Yagi:dipole relationships in your data\n",
    "2. nodes: List of nodes in your project, note nodes may be made up of one or more receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edges showing parent:child relationships for nodes in network\n",
    "edges = [('R010','R013'),('R010','R014'),('R010','R015'),('R010','R016'),('R010','R017'),('R010','R018'),\n",
    "          ('R019','R013'),('R019','R014'),('R019','R015'),('R019','R016'),('R019','R017'),('R019','R018'),\n",
    "          ('R020','R013'),('R020','R014'),('R020','R015'),('R020','R016'),('R020','R017'),('R020','R018')]\n",
    "\n",
    "nodes = ['R010','R019','R020','R013','R014','R015','R016','R017','R018']\n",
    "    \n",
    "# create an overlap object and apply nested doll algorithm\n",
    "doll = mast.overlap_reduction(nodes, edges, project)\n",
    "doll.nested_doll()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53467fa1",
   "metadata": {},
   "source": [
    "## Make Recaptures Table\n",
    "\n",
    "The last step in the data management section is to aggregate data into a recaptures table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eee09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.make_recaptures_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd1a09",
   "metadata": {},
   "source": [
    "# Part 3: Analysis of Movement\n",
    "\n",
    "The following cells assist researchers with analyzing movement between receivers.  It is useful to reconstruct the receivers in your project into a network schematic that describes the possible movement pathways between receivers. Therefore, movement is 1D.  MAST has functions that can prepare data for Time to Event Analysis with Competing Risks, Multi State Markov Models, Cormack Jolly Seber Mark Recapture, and Live Recapture Dead Recovery Mark Recapture.  \n",
    "\n",
    "## Model 1D Movement with Competing Risks and Multi-State Markov Models\n",
    "\n",
    "The first step in modeling multi-state models with a Time to Event framework is to associate project nodes with states in the model.  This is done with the node_to_state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create models using a Time to Event Framework\n",
    "    \n",
    "# what is the Node to State relationship - use Python dictionary\n",
    "node_to_state = {'R001':1,'R002':1,                   # upstream\n",
    "                 'R012':2,                            # forebay\n",
    "                 'R013':3,'R015':3,'R016':3,'R017':3, # powerhouse\n",
    "                 'R018':4,                            # sluice\n",
    "                 'R003':5,                            # east channel up\n",
    "                 'R007':6,                            # east channel down\n",
    "                 'R008':7,                            # east channel dam\n",
    "                 'R009':8,                            # NLF\n",
    "                 'R010':9,'R019':19,                  # tailrace\n",
    "                 'R011':10,                           # downstream\n",
    "                 'R004':11,'R005':11}                 # downstream 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aef50e",
   "metadata": {},
   "source": [
    "Then we create a Time to Event data object.  Note that there are a number of optional arguments that can be passed to the time to event data object.  If initial_state_release is set to True, a state (state: 0) is added to the model.  Therefore it is possible to model movement from the release location as well as determine fall back.  If last_presence_time0 is set to True, the last detection at the initial receiver is used as the starting time for the analysis of movement.  When modeling migratory movement of American Shad for example, adult fish can survive spawning.  Thus it can be recaptured at the same reciever on its way up and down.  If you are modeling downstream movement, you want to model movement from when it was last at the most upstream receiver.  Cap_loc and rel_loc are optional arguments that will filter the data in the model so it only looks at specimens at specific capture and release locations.  And finally, the species argument restricts model creation to a single species if more than 1 were tagged in your study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tte = formatter.time_to_event(node_to_state,\n",
    "                              project,\n",
    "                              initial_state_release = False, \n",
    "                              last_presence_time0 = False, \n",
    "                              cap_loc = None,\n",
    "                              rel_loc = None, \n",
    "                              species = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97c015",
   "metadata": {},
   "source": [
    "Then we perform data preparation.  When the time_dependent_covariates = True, MAST creates an output file that can be joined to time series data.  The bucket_length_min argument specifies the number of minutes between each time series observation.  Unknown_state places fish into a new 'unknown' state if they went missing before they reached their goal by the studies completion. Overlap may still exist between receivers and adjacency_filter removes those movements that still may exist.  This commonly happens when forebay receivers pick up fish in the tailrace.  When looking at transitions it appears that a fish has instantlh moved from the tailrace to the forebay.  To the algorithm, the forebay detections look like real detections, but when we model movement they must be removed.  The relationships in the filter specify the parent:child relationshp or to:from movements that are illegal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80177050",
   "metadata": {},
   "outputs": [],
   "source": [
    "tte.data_prep(project,\n",
    "              time_dependent_covariates = True,\n",
    "              unknown_state = None,\n",
    "              bucket_length_min = 15,\n",
    "              adjacency_filter = [('R010','R013'),('R010','R014'),('R010','R015'),('R010','R016'),('R010','R017'),('R010','R018'),\n",
    "                                  ('R019','R013'),('R019','R014'),('R019','R015'),('R019','R016'),('R019','R017'),('R019','R018'),\n",
    "                                  ('R020','R013'),('R020','R014'),('R020','R015'),('R020','R016'),('R020','R017'),('R020','R018')])\n",
    "# Step 4, generate a summary\n",
    "tte.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
