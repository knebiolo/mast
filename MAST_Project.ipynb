{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39725c4",
   "metadata": {},
   "source": [
    "# MAST \n",
    "## Movement Analysis Software for Telemetry Data\n",
    "\n",
    "This project notebook will guide the end user through a complete telemetry project, from setup, to data import, false positive reduction, and 1D movement analysis.  This notebook and software was designed so that the end user can complete a telemetry project in multiple sessions.  Some cells need to be re-run every session, while others will only be run once.  Please read and understand all directions before proceeding.\n",
    "\n",
    "# Part 1: Project Setup\n",
    "\n",
    "The steps in Part 1 need to be re-run every session.\n",
    "\n",
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748377b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bff69",
   "metadata": {},
   "source": [
    "Identify MAST software directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e303cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r\"C:\\Users\\knebiolo\\OneDrive - Kleinschmidt Associates, Inc\\Software\\mast\\pymast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53f911",
   "metadata": {},
   "source": [
    "Import MAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymast.radio_project import radio_project\n",
    "from pymast import formatter as formatter\n",
    "import pymast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103c6ee",
   "metadata": {},
   "source": [
    "# Create a MAST Project\n",
    "\n",
    "We designed MAST so that the end user can complete a telemetry project in multiple sessions.  After a work session is complete, there is no need to save the data or close the project.  Just shut down the notebook, the data has already been saved to the background HDF file.  When you start a new session, re-run this cell, MAST will not save over your previous session.  Please see the project ReadMe for instructions on creating the input data files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = r\"J:\\1871\\201\\Calcs\\York Haven\"\n",
    "db_name = 'york_haven'\n",
    "detection_count = 5\n",
    "duration = 1\n",
    "tag_data = pd.read_csv(os.path.join(project_dir,'tblMasterTag.csv'))\n",
    "receiver_data = pd.read_csv(os.path.join(project_dir,'tblMasterReceiver.csv'))\n",
    "nodes_data = pd.read_csv(os.path.join(project_dir,'tblNodes.csv'))\n",
    "\n",
    "# create a project\n",
    "project = radio_project(project_dir,\n",
    "                        db_name,\n",
    "                        detection_count,\n",
    "                        duration,\n",
    "                        tag_data,\n",
    "                        receiver_data,\n",
    "                        nodes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758de9b",
   "metadata": {},
   "source": [
    "# Part 2: Data management and False Positive Reduction\n",
    "\n",
    "## Import Raw Telemetry Data\n",
    "\n",
    "This cell **does not** need to be rerun every session.  \n",
    "\n",
    "To import raw telemetry data, update the parameters and run the cell for every receiver in your project\n",
    "\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type, we currently have parsers for 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'\n",
    "3. scan_time: if the Receiver Type is 'orion' or 'ares', enter channel scan time in seconds if any, otherwise keep 1\n",
    "4. channels: if the Receiver Type is 'orion' or 'ares', enter the number of channels if any, otherwise keep 1\n",
    "5. antenna_to_receiver_dict: both SigmaEight and Lotek associate one or more antennas to a single receiver.  This dictionary makes that association.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab024de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_id = 'T3'\n",
    "rec_type = 'srx800'\n",
    "training_dir = os.path.join(project_dir,'Data','Training_Files')\n",
    "db_dir = os.path.join(project_dir,'%s.h5'%(db_name))\n",
    "scan_time = 1.         \n",
    "channels = 1\n",
    "antenna_to_rec_dict = {'A0':rec_id}\n",
    "\n",
    "project.telem_data_import(rec_id,\n",
    "                          rec_type,\n",
    "                          training_dir,\n",
    "                          db_dir,\n",
    "                          scan_time,\n",
    "                          channels,\n",
    "                          antenna_to_rec_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90dd541",
   "metadata": {},
   "source": [
    "### Undo Import\n",
    "\n",
    "Sometimes thing's go wrong, sometimes the parameters you entered are incorrect.  Undo the import you just did with this cell.  \n",
    "\n",
    "Note **you only run the cell when you need to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_import(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0deaf",
   "metadata": {},
   "source": [
    "## Create Training Data\n",
    "\n",
    "This cell does **not** need to be run every work session\n",
    "\n",
    "To train data, update the following parameters for your telemetry project.  Repeat this cell until data from all receivers have been trained.\n",
    "\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type,  we currently have parsers for and can train and classify 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters and get a list of fish to iterate over\n",
    "rec_id = 'T3'\n",
    "rec_type = 'srx800'\n",
    "fishes = project.get_fish(rec_id = rec_id)\n",
    "\n",
    "# iterate over fish and train\n",
    "for fish in fishes:\n",
    "    project.train(fish, rec_id)\n",
    "\n",
    "# generate summary statistics\n",
    "project.training_summary(rec_type, site = [rec_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae90d3",
   "metadata": {},
   "source": [
    "### Undo Training\n",
    "\n",
    "**Run the following cell only when you need to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_training(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753fdee",
   "metadata": {},
   "source": [
    "## Classify a Receiver's Data\n",
    "\n",
    "This cell can be run as many times as needed.  \n",
    "\n",
    "To classify data, update the following parameters and run the cell.\n",
    "1. rec_id: the Receiver ID as written in the receiver data input file.\n",
    "2. rec_type: the Receiver Type,  we currently have parsers for and can train and classify 'orion','ares','srx400','srx600','srx800','srx1200', and 'VR2'\n",
    "3. class_iter: the Classification Iteration, it is possible to reclassify a receiver's data and iterate until convergence.  Leave 'Null' for the first iteration, then start with 1 and number sequentially by 1 until covergence.\n",
    "4. threshold_ratio: the default threshold ratio is 1.0 for the maximum a posteriori hypothesis.  a threshold ratio > 1.0 requires requires more weight of evidence for a record to be classified as true.  likewise a threshold ratio < 1.0 is less strict and may accept marginal detections as being true.\n",
    "5. fields: the likelihood function is A-La Carte, it is possible to build a model with the following predictors: 'cons_length','cons_length','hit_ratio','noise_ratio','series_hit','power', and 'lag_diff'.  Note MAST requires at least 1 predictor to classify data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32368df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters and get a list of fish to iterate over\n",
    "rec_id = 'R020'\n",
    "rec_type = 'orion'\n",
    "threshold_ratio = 1.0  # 1.0 = MAP Hypothesis\n",
    "# a-la carte likelihood, standard fields: ['hit_ratio', 'cons_length', 'noise_ratio', 'power', 'lag_diff']\n",
    "likelihood = ['hit_ratio', 'cons_length', 'noise_ratio', 'power', 'lag_diff'] \n",
    "\n",
    "project.reclassify(project, rec_id, rec_type, threshold_ratio,likelihood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40d1c0",
   "metadata": {},
   "source": [
    "### Undo Classification \n",
    "\n",
    "Lots can go wrong during classification, the likelihood model may have included conflicted predictors, the threshold ratio was too strict, or the iteration was wrong.  In any case, run the following cell when you need a redo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_classification(rec_id, class_iter = class_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925dd48",
   "metadata": {},
   "source": [
    "## Identify Bouts\n",
    "\n",
    "The following steps (Bouts and Presences) are not required for a MAST project.  They are powerful tools that will assist with modeling movement. \n",
    "To identify bouts at one of the nodes in your project, update the following parameters.  It is advised to identify bouts at nodes one at a time because model fitting requires user interaction.  MAST will ask the researcher to identify the number of knots that may be present in the data.  The presence method can either use the result of hte threshold method, or can accept a user identify threshold value (float).  \n",
    "\n",
    "1. node: A Node in your project that may consist of one or more receivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef339ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodes\n",
    "node = 'R020'\n",
    "\n",
    "# create a bout object\n",
    "bout = mast.bout(project, node, 2, 21600)\n",
    "    \n",
    "# Find the threshold\n",
    "threshold = bout.fit_processes()\n",
    "\n",
    "# calculate presences - or pass float\n",
    "bout.presence(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1eed79",
   "metadata": {},
   "source": [
    "### Undo Bouts and Presence\n",
    "\n",
    "The bout process involves trial and error.  To undo, run the following cell only when you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d86543",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_bouts(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dd08c",
   "metadata": {},
   "source": [
    "## Reduce Overlap\n",
    "\n",
    "With presences at receivers, it is possible to reduce overlap between receivers and put a fish in an exact place and time.  For example, it is possible to place a dipole receiver so it's detection range is completely within the area covered by a large aerial Yagi.  When a fish is present at the Dipole receiver and Yagi receiver at the same we can remove those overlapping detections at the Yagi receiver.  This is useful for modeling movement from a large area into a discrete location, like tailrace to upstream passage entrance.  \n",
    "\n",
    "The overlap function requires the end user to identify the following parameters:\n",
    "1. edges: List of tuples (network edges) that represent parent:child or Yagi:dipole relationships in your data\n",
    "2. nodes: List of nodes in your project, note nodes may be made up of one or more receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edges showing parent:child relationships for nodes in network\n",
    "edges = [('R010','R013'),('R010','R014'),('R010','R015'),('R010','R016'),('R010','R017'),('R010','R018'),\n",
    "          ('R019','R013'),('R019','R014'),('R019','R015'),('R019','R016'),('R019','R017'),('R019','R018'),\n",
    "          ('R020','R013'),('R020','R014'),('R020','R015'),('R020','R016'),('R020','R017'),('R020','R018')]\n",
    "\n",
    "nodes = ['R010','R019','R020','R013','R014','R015','R016','R017','R018']\n",
    "    \n",
    "# create an overlap object and apply nested doll algorithm\n",
    "doll = mast.overlap_reduction(nodes, edges, project)\n",
    "doll.nested_doll()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f10d52-1c5f-45ff-9470-8b3dfa9a5edc",
   "metadata": {},
   "source": [
    "Undo overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e185b3b-c3b0-4571-a77f-69c96db0b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_overlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53467fa1",
   "metadata": {},
   "source": [
    "## Make Recaptures Table\n",
    "\n",
    "The last step in the data management section is to aggregate data into a recaptures table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eee09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.make_recaptures_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea435c8-38b4-404f-8044-677d98290947",
   "metadata": {},
   "source": [
    "Unde Recaptures Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cc344-3eb5-4050-8ebd-11ff974f356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.undo_recaptures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd1a09",
   "metadata": {},
   "source": [
    "# Part 3: Analysis of Movement\n",
    "\n",
    "The following cells assist researchers with analyzing movement between receivers.  It is useful to reconstruct the receivers in your project into a network schematic that describes the possible movement pathways between receivers. Therefore, movement is 1D.  MAST has functions that can prepare data for Time to Event Analysis with Competing Risks, Multi State Markov Models, Cormack Jolly Seber Mark Recapture, and Live Recapture Dead Recovery Mark Recapture.  \n",
    "\n",
    "## Model 1D Movement with Competing Risks and Multi-State Markov Models\n",
    "\n",
    "The first step in modeling multi-state models with a Time to Event framework is to associate project nodes with states in the model.  This is done with the node_to_state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create models using a Time to Event Framework\n",
    "    \n",
    "# what is the Node to State relationship - use Python dictionary\n",
    "node_to_state = {'R001':1,'R002':1,                   # upstream\n",
    "                  'R012':2,                            # forebay\n",
    "                  'R013':3,'R015':3,'R016':3,'R017':3, # powerhouse\n",
    "                  'R018':4,                            # sluice\n",
    "                  'R003':5,                            # east channel up\n",
    "                  'R007':6,                            # east channel down\n",
    "                  'R008':7,                            # east channel dam\n",
    "                  'R009':8,                            # NLF\n",
    "                  'R010':9,'R019':19,                  # tailrace\n",
    "                  'R011':10,                           # downstream\n",
    "                  'R004':11,'R005':11}                 # downstream 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aef50e",
   "metadata": {},
   "source": [
    "Then we create a Time to Event data object.  Note that there are a number of optional arguments that can be passed to the time to event data object.  If initial_state_release is set to True, a state (state: 0) is added to the model.  Therefore it is possible to model movement from the release location as well as determine fall back.  If last_presence_time0 is set to True, the last detection at the initial receiver is used as the starting time for the analysis of movement.  When modeling migratory movement of American Shad for example, adult fish can survive spawning.  Thus it can be recaptured at the same reciever on its way up and down.  If you are modeling downstream movement, you want to model movement from when it was last at the most upstream receiver.  Cap_loc and rel_loc are optional arguments that will filter the data in the model so it only looks at specimens at specific capture and release locations.  And finally, the species argument restricts model creation to a single species if more than 1 were tagged in your study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tte = formatter.time_to_event(node_to_state,\n",
    "                              project,\n",
    "                              initial_state_release = False, \n",
    "                              last_presence_time0 = False, \n",
    "                              cap_loc = None,\n",
    "                              rel_loc = None, \n",
    "                              species = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97c015",
   "metadata": {},
   "source": [
    "Then we perform data preparation.  When the time_dependent_covariates = True, MAST creates an output file that can be joined to time series data.  The bucket_length_min argument specifies the number of minutes between each time series observation.  Unknown_state places fish into a new 'unknown' state if they went missing before they reached their goal by the studies completion. Overlap may still exist between receivers and adjacency_filter removes those movements that still may exist.  This commonly happens when forebay receivers pick up fish in the tailrace.  When looking at transitions it appears that a fish has moved from the tailrace to the forebay.  To the algorithm, the forebay detections look like real detections, but when we model movement they must be removed.  The relationships in the filter specify the parent:child relationshp or to:from movements that are illegal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80177050",
   "metadata": {},
   "outputs": [],
   "source": [
    "tte.data_prep(project,\n",
    "              time_dependent_covariates = True,\n",
    "              unknown_state = None,\n",
    "              bucket_length_min = 15,\n",
    "              adjacency_filter = [('R010','R013'),('R010','R014'),('R010','R015'),('R010','R016'),('R010','R017'),('R010','R018'),\n",
    "                                  ('R019','R013'),('R019','R014'),('R019','R015'),('R019','R016'),('R019','R017'),('R019','R018'),\n",
    "                                  ('R020','R013'),('R020','R014'),('R020','R015'),('R020','R016'),('R020','R017'),('R020','R018')])\n",
    "# Step 4, generate a summary\n",
    "tte.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd5ff4-48ae-4ab6-9336-54034c485f8e",
   "metadata": {},
   "source": [
    "The next cell creates a time to event dataset without covariates, if all your after is a Kaplan Meier, this is the one to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26098b99-7e52-4bc5-b4e1-93bc1a4fd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "tte.data_prep(project,\n",
    "              adjacency_filter = [('R010','R013'),('R010','R014'),('R010','R015'),('R010','R016'),('R010','R017'),('R010','R018'),\n",
    "                                  ('R019','R013'),('R019','R014'),('R019','R015'),('R019','R016'),('R019','R017'),('R019','R018'),\n",
    "                                  ('R020','R013'),('R020','R014'),('R020','R015'),('R020','R016'),('R020','R017'),('R020','R018')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191394b5-6759-4634-a90d-45bd08f63b02",
   "metadata": {},
   "source": [
    "## Cormack Jolly Seber Mark Recapture\n",
    "\n",
    "The Cormack Jolly Seber (CJS) model is appropriate for a simple analysis of fish ladder effectiveness.  The following cells produce the detection history INP file that can be used with MARK or RMARK.  The first step is to identify sone parameters and associate study receivers with recapture occasions in the model.  We do that with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c0ea1-7966-462c-b6f4-561e11ee206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"york_haven\"\n",
    "output_ws = os.path.join(project_dir, 'Output')\n",
    "\n",
    "# what is the Node to State relationship - use Python dictionary\n",
    "receiver_to_recap = {'R001':'R01','R002':'R01',\n",
    "                     'R003':'R02','R004':'R04','R005':'R04','R006':'R02',\n",
    "                     'R007':'R02','R008':'R02','R009':'R02','R010':'R02',\n",
    "                     'R011':'R03','R012':'R02','R013':'R02','R014':'R02',\n",
    "                     'R015':'R02','R016':'R02','R017':'R02',#'R018':'R02',\n",
    "                     'R019':'R03','R020':'R03',}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea149ec3-44aa-4879-ae38-c283f5dc5f7b",
   "metadata": {},
   "source": [
    "The next cell produces a cjs data object and input files for analysis with Mark Recapture software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35539c-a80f-471f-9ed6-c5634b2f7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1, create CJS data object\n",
    "cjs = formatter.cjs_data_prep(receiver_to_recap, project, initial_recap_release = False)\n",
    "\n",
    "# Step 2, Create input file for MARK\n",
    "cjs.input_file(model_name,output_ws)\n",
    "cjs.inp.to_csv(os.path.join(output_ws,model_name + '.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
