{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfa6cac",
   "metadata": {},
   "source": [
    "# PyMAST Complete Project Workflow\n",
    "## Movement Analysis Software for Telemetry Data\n",
    "\n",
    "![PyMAST Logo](pymast_logo.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What This Notebook Does\n",
    "\n",
    "This notebook will guide you through analyzing your radio telemetry data from start to finish. **No programming experience required!** Just follow along, update the values in CAPITAL LETTERS with your own information, and press the \"Run\" button (â–¶ï¸) on each cell.\n",
    "\n",
    "### What You'll Accomplish:\n",
    "\n",
    "1. **Load your project** - Connect to your fish tracking data\n",
    "2. **Import receiver files** - Bring in detection data from the field\n",
    "3. **Clean the data** (optional) - Remove false detections using AI\n",
    "4. **Find fish visits** - Identify when fish were at each location\n",
    "5. **Resolve overlaps** - Handle fish detected by multiple receivers\n",
    "6. **Export for analysis** - Create files for statistical software\n",
    "\n",
    "### â±ï¸ Time Required: \n",
    "- **First time**: 2-4 hours (depending on data size)\n",
    "- **Repeat sessions**: 5-10 minutes (just run setup cells)\n",
    "\n",
    "### ğŸ’¾ What You Need Before Starting:\n",
    "\n",
    "Create a folder on your computer with these files:\n",
    "- `tblMasterTag.csv` - Information about your fish tags (tag IDs, pulse rates, etc.)\n",
    "- `tblMasterReceiver.csv` - Information about your receivers (receiver IDs, locations)\n",
    "- `tblNodes.csv` - Locations/areas you're studying (optional)\n",
    "- A folder called `Data` with a subfolder `Raw_Files` containing your receiver download files\n",
    "\n",
    "### ğŸ“– How to Use This Notebook:\n",
    "\n",
    "1. **Read the text in each section** - It explains what's happening\n",
    "2. **Look for ğŸ”§ EDIT THIS** markers - These tell you what to change\n",
    "3. **Click the cell and press Shift+Enter** - This runs the code\n",
    "4. **Wait for the âœ“ checkmark** - This means it worked!\n",
    "5. **If you see an error** - Read it carefully, it usually tells you what's wrong\n",
    "\n",
    "### ğŸ’¡ Pro Tips:\n",
    "\n",
    "- **Run cells in order** - Don't skip around or things will break\n",
    "- **Save often** - Use Ctrl+S or File â†’ Save\n",
    "- **You can't break anything permanently** - The database keeps backups\n",
    "- **Green text starting with #** - These are comments, just notes for you\n",
    "- **Lines starting with #** - Won't run, they're turned off (you can turn them on by removing the #)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Ready? Let's Start!\n",
    "\n",
    "**First step**: Scroll down to Section 1.1 and click the Run button (â–¶ï¸) to load the software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274d131",
   "metadata": {},
   "source": [
    "# Part 1: Project Setup\n",
    "\n",
    "**Run these cells every session** to load modules and connect to your project database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2948a1",
   "metadata": {},
   "source": [
    "## 1.1 Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure PyMAST is importable\n",
    "try:\n",
    "    import pymast\n",
    "except ImportError:\n",
    "    # Add PyMAST to path if not installed via pip\n",
    "    repo_root = Path.cwd().parent if 'scripts' in str(Path.cwd()) else Path.cwd()\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "    import pymast\n",
    "\n",
    "from pymast.radio_project import radio_project\n",
    "from pymast import formatter\n",
    "from pymast.overlap_removal import bout, overlap_reduction\n",
    "\n",
    "print(f\"PyMAST version: {pymast.__version__ if hasattr(pymast, '__version__') else 'unknown'}\")\n",
    "print(f\"Python executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6f9745",
   "metadata": {},
   "source": [
    "## 1.2 Initialize or Load Project\n",
    "\n",
    "**First time:** Creates new HDF5 database with your metadata  \n",
    "**Subsequent sessions:** Reconnects to existing database\n",
    "\n",
    "**Required files in `project_dir`:**\n",
    "- `tblMasterTag.csv` - Tag metadata (freq_code, pulse_rate, tag_type, etc.)\n",
    "- `tblMasterReceiver.csv` - Receiver metadata (rec_id, rec_type, node, lat/lon)\n",
    "- `tblNodes.csv` - Spatial nodes for movement modeling (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d020d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT CONFIGURATION\n",
    "project_dir = r\"C:\\path\\to\\your\\project\"  # Update this path!\n",
    "db_name = 'my_telemetry_study'\n",
    "\n",
    "# Load metadata\n",
    "tag_data = pd.read_csv(os.path.join(project_dir, 'tblMasterTag.csv'))\n",
    "receiver_data = pd.read_csv(os.path.join(project_dir, 'tblMasterReceiver.csv'))\n",
    "nodes_data = pd.read_csv(os.path.join(project_dir, 'tblNodes.csv'))\n",
    "\n",
    "# Initialize project\n",
    "project = radio_project(\n",
    "    project_dir=project_dir,\n",
    "    db_name=db_name,\n",
    "    detection_count=5,  # Minimum detections for valid bout\n",
    "    duration=1,         # Time window for detection clustering (minutes)\n",
    "    tag_data=tag_data,\n",
    "    receiver_data=receiver_data,\n",
    "    nodes_data=nodes_data\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Project initialized: {project.db}\")\n",
    "print(f\"  Tags: {len(tag_data)}\")\n",
    "print(f\"  Receivers: {len(receiver_data)}\")\n",
    "print(f\"  Nodes: {len(nodes_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec2c2c",
   "metadata": {},
   "source": [
    "### Optional: Create New Database Version\n",
    "\n",
    "Uncomment to create a new version while preserving original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec550b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.new_db_version(os.path.join(project_dir, f'{db_name}_v2.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af574c62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Data Import\n",
    "\n",
    "**Run once per receiver** to import raw detection files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8cc47",
   "metadata": {},
   "source": [
    "## 2.1 Import Receiver Data\n",
    "\n",
    "**Supported receiver types:**\n",
    "- Lotek: `srx1200`, `srx800`, `srx600`\n",
    "- Sigma Eight: `orion`, `ares`\n",
    "- Vemco: `vr2`\n",
    "\n",
    "**Update these parameters for each receiver:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECEIVER IMPORT CONFIGURATION\n",
    "rec_id = 'REC001'              # Receiver ID from tblMasterReceiver.csv\n",
    "rec_type = 'srx1200'           # Receiver type\n",
    "scan_time = 2.5                # Scan duration per channel (seconds)\n",
    "channels = 1                   # Number of receiver channels\n",
    "antenna_to_rec_dict = {'A0': rec_id}  # Antenna to receiver mapping\n",
    "\n",
    "# Directory containing raw detection files\n",
    "data_dir = os.path.join(project_dir, 'Data', 'Raw_Files')\n",
    "db_dir = os.path.join(project_dir, f'{db_name}.h5')\n",
    "\n",
    "# Import data\n",
    "project.telem_data_import(\n",
    "    rec_id=rec_id,\n",
    "    rec_type=rec_type,\n",
    "    file_dir=data_dir,\n",
    "    db_dir=db_dir,\n",
    "    scan_time=scan_time,\n",
    "    channels=channels,\n",
    "    ant_to_rec_dict=antenna_to_rec_dict\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Imported data for {rec_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1786bb4",
   "metadata": {},
   "source": [
    "### Undo Import (if needed)\n",
    "\n",
    "Run only if you need to re-import with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e12b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.undo_import(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf1d45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Classification (Optional)\n",
    "\n",
    "Train a Naive Bayes classifier to identify and remove false positive detections.\n",
    "\n",
    "**Skip this section if:**\n",
    "- You don't have hand-labeled training data\n",
    "- False positives are minimal in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da71002",
   "metadata": {},
   "source": [
    "## 3.1 Train Classifier\n",
    "\n",
    "**Run once per receiver** after creating training data via manual labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ade48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CONFIGURATION\n",
    "rec_id = 'REC001'\n",
    "rec_type = 'srx1200'\n",
    "\n",
    "# Get list of fish detected at this receiver\n",
    "fishes = project.get_fish(rec_id=rec_id)\n",
    "print(f\"Training classifier for {len(fishes)} fish at {rec_id}...\")\n",
    "\n",
    "# Train classifier for each fish\n",
    "for fish in fishes:\n",
    "    project.train(fish, rec_id)\n",
    "\n",
    "# Generate training summary statistics\n",
    "project.training_summary(rec_type, site=[rec_id])\n",
    "\n",
    "print(\"\\nâœ“ Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6523ed",
   "metadata": {},
   "source": [
    "### Undo Training (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.undo_training(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e336b4",
   "metadata": {},
   "source": [
    "## 3.2 Classify Detections\n",
    "\n",
    "Apply trained classifier to identify false positives.\n",
    "\n",
    "**Likelihood predictors** (Ã€ la carte - choose any combination):\n",
    "- `hit_ratio`: Proportion of detections matching expected pulse intervals\n",
    "- `cons_length`: Maximum contiguous sequence of expected detections\n",
    "- `noise_ratio`: Ratio of miscoded to total detections\n",
    "- `power`: Signal strength\n",
    "- `lag_diff`: Variability in inter-detection intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce04a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION CONFIGURATION\n",
    "rec_id = 'REC001'\n",
    "rec_type = 'srx1200'\n",
    "threshold_ratio = 1.0  # 1.0 = MAP hypothesis (balanced), >1.0 = stricter, <1.0 = more permissive\n",
    "\n",
    "# Select likelihood predictors\n",
    "likelihood = ['hit_ratio', 'cons_length', 'noise_ratio', 'power', 'lag_diff']\n",
    "\n",
    "# Classify detections\n",
    "project.reclassify(\n",
    "    project=project,\n",
    "    rec_id=rec_id,\n",
    "    rec_type=rec_type,\n",
    "    threshold_ratio=threshold_ratio,\n",
    "    likelihood_model=likelihood\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Classification complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0786a",
   "metadata": {},
   "source": [
    "### Undo Classification (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.undo_classification(rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59cb068",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Bout Detection with DBSCAN\n",
    "\n",
    "Identify continuous presence periods using density-based clustering.\n",
    "\n",
    "**DBSCAN Parameters:**\n",
    "- `eps_multiplier`: Sets temporal threshold (epsilon = pulse_rate Ã— eps_multiplier)\n",
    "  - Default: 5 (~40-50 seconds for typical 8-10 sec tags)\n",
    "  - Higher values = longer gaps allowed within bouts\n",
    "- `lag_window`: Legacy parameter (kept for compatibility, not used in clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6d484c",
   "metadata": {},
   "source": [
    "## 4.1 Run Bout Detection for All Receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally undo existing bouts if re-running\n",
    "# project.undo_bouts()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BOUT DETECTION (DBSCAN)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "receivers = list(project.receivers.index)\n",
    "print(f\"\\nProcessing {len(receivers)} receivers...\\n\")\n",
    "\n",
    "successful_receivers = []\n",
    "failed_receivers = []\n",
    "\n",
    "for rec_id in receivers:\n",
    "    try:\n",
    "        print(f\"[{rec_id}] Starting bout detection...\")\n",
    "        \n",
    "        # Create bout object - DBSCAN runs automatically during init\n",
    "        bout_obj = bout(\n",
    "            radio_project=project,\n",
    "            rec_id=rec_id,\n",
    "            eps_multiplier=5,  # 5Ã— pulse rate for temporal clustering\n",
    "            lag_window=9       # Legacy parameter (not used in DBSCAN)\n",
    "        )\n",
    "        \n",
    "        # Cluster detections into bouts\n",
    "        bout_obj.cluster()\n",
    "        \n",
    "        # Visualize bout lengths (creates diagnostic plots)\n",
    "        bout_obj.visualize_bout_lengths()\n",
    "        \n",
    "        successful_receivers.append(rec_id)\n",
    "        print(f\"[{rec_id}] âœ“ Complete\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_receivers.append(rec_id)\n",
    "        print(f\"[{rec_id}] âœ— Failed: {e}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Bout Detection Summary:\")\n",
    "print(f\"  Successful: {len(successful_receivers)}\")\n",
    "print(f\"  Failed: {len(failed_receivers)}\")\n",
    "if failed_receivers:\n",
    "    print(f\"  Failed receivers: {', '.join(failed_receivers)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8ba25",
   "metadata": {},
   "source": [
    "### Undo Bouts (if needed)\n",
    "\n",
    "Undo all bouts or specific receiver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo all bouts\n",
    "# project.undo_bouts()\n",
    "\n",
    "# Undo specific receiver\n",
    "# project.undo_bouts(rec_id='REC001')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79fb8f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Overlap Resolution\n",
    "\n",
    "Resolve spatially ambiguous detections when fish are detected by multiple receivers simultaneously.\n",
    "\n",
    "**Two methods available:**\n",
    "1. **Unsupervised** - Statistical comparison (t-test + Cohen's d) of signal power/posterior\n",
    "2. **Nested Doll** - Hierarchical removal based on parent-child receiver relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed2c45",
   "metadata": {},
   "source": [
    "## 5.1 Unsupervised Overlap Resolution (Recommended)\n",
    "\n",
    "Uses statistical testing to identify stronger signal receiver.\n",
    "\n",
    "**Parameters:**\n",
    "- `method`: `'power'` or `'posterior'` for comparison metric\n",
    "- `p_value_threshold`: Require statistical significance (default: 0.05)\n",
    "- `effect_size_threshold`: Minimum Cohen's d (default: 0.2 = small effect)\n",
    "- `min_detections`: Minimum bout size for comparison (default: 5)\n",
    "- `bout_expansion`: Time buffer for near-overlaps in seconds (default: 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21909f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define network structure\n",
    "nodes = list(project.receivers.index)\n",
    "edges = [(i, j) for i in nodes for j in nodes if i != j]  # All possible receiver pairs\n",
    "\n",
    "print(\"Initializing overlap reduction...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create overlap reduction object\n",
    "overlap_obj = overlap_reduction(\n",
    "    nodes=nodes,\n",
    "    edges=edges,\n",
    "    radio_project=project\n",
    ")\n",
    "\n",
    "# Run unsupervised removal with statistical testing\n",
    "print(\"Running unsupervised overlap resolution...\")\n",
    "overlap_obj.unsupervised(\n",
    "    # method='power',              # Compare signal power\n",
    "    # p_value_threshold=0.05,      # Require p < 0.05\n",
    "    # effect_size_threshold=0.2,   # Small effect size\n",
    "    # min_detections=5,            # Minimum bout size\n",
    "    # bout_expansion=60            # Â±60 second buffer\n",
    ")\n",
    "\n",
    "# Visualize overlap analysis (creates 8-panel diagnostic plot)\n",
    "overlap_obj.visualize_overlaps()\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nâœ“ Overlap resolution complete ({elapsed:.1f} seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcda30",
   "metadata": {},
   "source": [
    "## 5.2 Nested Doll Overlap Resolution (Alternative)\n",
    "\n",
    "Hierarchical removal based on known parent-child receiver relationships.\n",
    "\n",
    "**Use when:**\n",
    "- You have directional antennas with known coverage hierarchy\n",
    "- Small dipole receivers within larger Yagi coverage areas\n",
    "- Clear spatial containment relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d6cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parent:child relationships (outer receiver : inner receiver)\n",
    "# edges = [\n",
    "#     ('R04', 'R15'), ('R04', 'R14'), ('R04', 'R13'),  # R04 contains R15, R14, R13...\n",
    "#     ('R03', 'R15'), ('R03', 'R14'), ('R03', 'R13'),  # R03 contains R15, R14, R13...\n",
    "#     ('R08', 'R10'),                                   # R08 contains R10\n",
    "#     ('R09', 'R10')                                    # R09 contains R10\n",
    "# ]\n",
    "# nodes = ['R03', 'R04', 'R05', 'R08', 'R09', 'R10', 'R12', 'R13', 'R14', 'R15']\n",
    "\n",
    "# # Create overlap object and apply nested doll algorithm\n",
    "# nested_obj = overlap_reduction(\n",
    "#     nodes=nodes,\n",
    "#     edges=edges,\n",
    "#     radio_project=project\n",
    "# )\n",
    "# nested_obj.nested_doll()\n",
    "\n",
    "# print(\"\\nâœ“ Nested doll overlap resolution complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12002131",
   "metadata": {},
   "source": [
    "### Undo Overlap Resolution (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.undo_overlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c19282",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Create Recaptures Table\n",
    "\n",
    "Aggregate all detections into spatially/temporally resolved recaptures table.\n",
    "\n",
    "**This table:**\n",
    "- Links detections to spatial nodes\n",
    "- Applies classification and overlap decisions\n",
    "- Serves as input for all statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389942b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recaptures table\n",
    "project.make_recaptures_table(export=True)\n",
    "\n",
    "print(\"\\nâœ“ Recaptures table created\")\n",
    "print(f\"  Exported to: {os.path.join(project_dir, 'Output', 'recaptures.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c834dd",
   "metadata": {},
   "source": [
    "### Undo Recaptures (if needed)\n",
    "\n",
    "Optionally repack database after undo to reclaim disk space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29037dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project.undo_recaptures()\n",
    "# project.repack_database()  # Reclaim disk space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03f7c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: Movement Analysis\n",
    "\n",
    "Export data for survival/movement models.\n",
    "\n",
    "**Available formats:**\n",
    "1. **Time-to-Event (TTE)** - Competing risks, multi-state models (R survival package)\n",
    "2. **Cormack-Jolly-Seber (CJS)** - Mark-recapture (Program MARK/RMark)\n",
    "3. **Live-Recapture Dead-Recovery (LRDR)** - Dual recovery models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc6c7f5",
   "metadata": {},
   "source": [
    "## 7.1 Time-to-Event Model\n",
    "\n",
    "Export data for competing risks and multi-state Markov models.\n",
    "\n",
    "**Step 1:** Define node-to-state mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map spatial nodes to model states\n",
    "node_to_state = {\n",
    "    'R15': 1, 'R14': 1,              # Occum Pond (upstream)\n",
    "    'R13': 2, 'R12': 2,              # Downstream gate\n",
    "    'R10': 3,                         # Tailrace\n",
    "    'R11': 4,                         # Fish lift entrance\n",
    "    'R08': 5, 'R09': 5,              # Spillway\n",
    "    'R06': 6, 'R07': 6,              # Surface bypass\n",
    "    'R05': 7,                         # Submerged bypass\n",
    "    'R04': 8,                         # Fish lift exit\n",
    "    'R03': 9,                         # Forebay\n",
    "    'R01': 10, 'R02': 10             # Windham (downstream)\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(set(node_to_state.values()))} states from {len(node_to_state)} receivers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af91a49",
   "metadata": {},
   "source": [
    "**Step 2:** Create time-to-event data object\n",
    "\n",
    "**Optional parameters:**\n",
    "- `initial_state_release=True`: Add state 0 for release location (models fallback)\n",
    "- `last_presence_time0=True`: Use last detection at initial receiver as t=0 (for downstream migration)\n",
    "- `cap_loc`: Filter by capture location\n",
    "- `rel_loc`: Filter by release location\n",
    "- `species`: Filter by species (if multi-species study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6913bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TTE data object\n",
    "tte = formatter.time_to_event(\n",
    "    node_to_state=node_to_state,\n",
    "    radio_project=project,\n",
    "    initial_state_release=True,   # Add release state (state 0)\n",
    "    last_presence_time0=False,    # t=0 at first detection\n",
    "    cap_loc=None,                 # All capture locations\n",
    "    rel_loc='tailrace',           # Filter by release location\n",
    "    species=None,                 # All species\n",
    "    recap_date=None               # All dates\n",
    ")\n",
    "\n",
    "print(\"âœ“ TTE data object created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdfa14",
   "metadata": {},
   "source": [
    "**Step 3:** Prepare data with adjacency filter\n",
    "\n",
    "**Adjacency filter** removes impossible movements (e.g., forebay â†’ tailrace without passing through dam).\n",
    "\n",
    "Specify illegal (from_state, to_state) transitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ad50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define illegal state transitions (from_state, to_state)\n",
    "adjacency_filter = [\n",
    "    (9, 1), (9, 2), (9, 3),  # Forebay can't jump to upstream states\n",
    "    (8, 1), (8, 2), (8, 3),  # Lift exit can't jump to upstream\n",
    "    (1, 8), (1, 9),          # Upstream can't teleport to forebay/exit\n",
    "    (2, 9), (2, 8),          # Gate can't skip to forebay/exit\n",
    "    (3, 8), (3, 9)           # Tailrace can't jump to forebay/exit\n",
    "]\n",
    "\n",
    "# Prepare data (applies adjacency filter)\n",
    "tte.data_prep(\n",
    "    radio_project=project,\n",
    "    adjacency_filter=adjacency_filter\n",
    ")\n",
    "\n",
    "# Generate summary statistics\n",
    "stats = tte.summary()\n",
    "\n",
    "print(\"\\nâœ“ TTE data preparation complete\")\n",
    "print(f\"  Movement summary: {os.path.join(project_dir, 'Output', 'movement_summary.csv')}\")\n",
    "print(f\"  State table: {os.path.join(project_dir, 'Output', 'state_table.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3a6bc",
   "metadata": {},
   "source": [
    "### View TTE Output Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c33d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display TTE output tables\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "output_dir = os.path.join(project_dir, \"Output\")\n",
    "df_movement = pd.read_csv(os.path.join(output_dir, \"movement_summary.csv\"))\n",
    "df_state = pd.read_csv(os.path.join(output_dir, \"state_table.csv\"))\n",
    "\n",
    "print(\"=== Movement Summary ===\")\n",
    "print(df_movement)\n",
    "print(\"\\n=== State Table (first 10 rows) ===\")\n",
    "print(df_state.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d723666",
   "metadata": {},
   "source": [
    "## 7.2 Cormack-Jolly-Seber Model\n",
    "\n",
    "Simple mark-recapture analysis (e.g., fish ladder effectiveness).\n",
    "\n",
    "**Step 1:** Map receivers to recapture occasions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64945dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map receivers to recapture occasions\n",
    "receiver_to_recap = {\n",
    "    'R01': 'R01', 'R02': 'R01',              # Occasion 1: Downstream\n",
    "    'R10': 'R02', 'R12': 'R02',              # Occasion 2: Tailrace\n",
    "    'R13': 'R03', 'R14': 'R03',              # Occasion 3: Dam\n",
    "    'R15': 'R04', 'R16': 'R04',              # Occasion 4: Upstream\n",
    "    'R03': 'R05', 'R04': 'R05'               # Occasion 5: Forebay\n",
    "}\n",
    "\n",
    "model_name = \"my_study_cjs\"\n",
    "output_ws = os.path.join(project_dir, 'Output')\n",
    "\n",
    "print(f\"Defined {len(set(receiver_to_recap.values()))} recapture occasions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e14e820",
   "metadata": {},
   "source": [
    "**Step 2:** Create CJS input file for Program MARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CJS data object\n",
    "cjs = formatter.cjs_data_prep(\n",
    "    receiver_to_recap=receiver_to_recap,\n",
    "    radio_project=project,\n",
    "    species=None,                    # All species\n",
    "    initial_recap_release=False      # First detection is first recapture\n",
    ")\n",
    "\n",
    "# Generate MARK input file\n",
    "cjs.input_file(model_name, output_ws)\n",
    "cjs.inp.to_csv(os.path.join(output_ws, f'{model_name}.csv'), index=False)\n",
    "\n",
    "print(\"\\nâœ“ CJS input file created\")\n",
    "print(f\"  INP file: {os.path.join(output_ws, f'{model_name}.inp')}\")\n",
    "print(f\"  CSV file: {os.path.join(output_ws, f'{model_name}.csv')}\")\n",
    "print(\"\\n  Next step: Import .inp file into Program MARK or RMark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcbadd7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 8: Quality Control & Visualization\n",
    "\n",
    "Visual inspection of fish movement histories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7e2e6",
   "metadata": {},
   "source": [
    "## 8.1 Fish Movement Histories (3D Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymast.fish_history import fish_history\n",
    "\n",
    "# # Load fish tracks\n",
    "# fh = fish_history(\n",
    "#     projectDB=project.db,\n",
    "#     filtered=True,          # Show only filtered detections (test==0)\n",
    "#     overlapping=False       # Exclude overlapping detections\n",
    "# )\n",
    "\n",
    "# # View specific fish\n",
    "# fh.change_fish('166.380 7')\n",
    "# fh.plot_3d_trajectory()\n",
    "\n",
    "# print(\"\\nâœ“ Fish history visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794b33d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "**Your PyMAST project is complete!**\n",
    "\n",
    "**Output files created:**\n",
    "- `{db_name}.h5` - HDF5 database with all processed data\n",
    "- `Output/movement_summary.csv` - TTE movement summary\n",
    "- `Output/state_table.csv` - TTE state transitions\n",
    "- `Output/recaptures.csv` - Spatiotemporal recaptures table\n",
    "- `Output/{model_name}.inp` - MARK input file (if CJS created)\n",
    "\n",
    "**Next steps:**\n",
    "1. Import TTE data into R (`survival` package) for competing risks models\n",
    "2. Import CJS .inp file into Program MARK or RMark for mark-recapture analysis\n",
    "3. Review diagnostic plots for quality control\n",
    "4. Iterate on adjacency filters if impossible movements detected\n",
    "\n",
    "**Documentation:**\n",
    "- [GETTING_STARTED.md](GETTING_STARTED.md) - Complete setup guide\n",
    "- [ARCHITECTURE.md](ARCHITECTURE.md) - System overview and database structure\n",
    "- Python help system: `help(pymast.module_name)`\n",
    "\n",
    "---\n",
    "\n",
    "**PyMAST** - Movement Analysis Software for Telemetry  \n",
    "https://github.com/knebiolo/mast"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
